"""
RFS v4.1 Cold Start Optimizer
ì„œë²„ë¦¬ìŠ¤ í™˜ê²½(Cloud Run)ì—ì„œ Cold Start ì§€ì—° ìµœì†Œí™”

ì£¼ìš” ê¸°ëŠ¥:
- ëª¨ë“ˆ ì‚¬ì „ ë¡œë”©
- ìºì‹œ ì›Œë°ì—…
- ë©”ëª¨ë¦¬ ìµœì í™”
- ì‹œì‘ ì‹œê°„ ì¸¡ì • ë° ë¶„ì„
- ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
"""

import time
import asyncio
import gc
import sys
import importlib
import threading
from typing import Dict, List, Optional, Callable, Any, Set
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
import psutil
import os

logger = logging.getLogger(__name__)


class OptimizationLevel(Enum):
    """ìµœì í™” ìˆ˜ì¤€"""
    MINIMAL = "minimal"      # ê¸°ë³¸ì ì¸ ìµœì í™”ë§Œ
    MODERATE = "moderate"    # ê· í˜•ìˆëŠ” ìµœì í™”
    AGGRESSIVE = "aggressive" # ìµœëŒ€ ì„±ëŠ¥ ìµœì í™”


@dataclass
class StartupMetrics:
    """ì‹œì‘ ë©”íŠ¸ë¦­"""
    total_startup_time: float = 0.0
    import_time: float = 0.0
    initialization_time: float = 0.0
    warmup_time: float = 0.0
    gc_time: float = 0.0
    
    # ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­
    initial_memory_mb: float = 0.0
    final_memory_mb: float = 0.0
    memory_saved_mb: float = 0.0
    
    # ëª¨ë“ˆ ë©”íŠ¸ë¦­
    preloaded_modules: int = 0
    failed_imports: int = 0
    cached_objects: int = 0
    
    # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
    cpu_cores: int = 0
    available_memory_mb: float = 0.0
    python_version: str = ""
    
    def __post_init__(self):
        if not self.python_version:
            self.python_version = f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
        if not self.cpu_cores:
            self.cpu_cores = os.cpu_count() or 1
        if not self.available_memory_mb:
            self.available_memory_mb = psutil.virtual_memory().available / (1024 * 1024)


@dataclass
class OptimizationConfig:
    """ìµœì í™” ì„¤ì •"""
    level: OptimizationLevel = OptimizationLevel.MODERATE
    
    # ëª¨ë“ˆ ì‚¬ì „ ë¡œë”©
    preload_modules: List[str] = field(default_factory=list)
    preload_patterns: List[str] = field(default_factory=list)  # íŒ¨í„´ ê¸°ë°˜ ë¡œë”©
    max_preload_time: float = 5.0  # ìµœëŒ€ ì‚¬ì „ ë¡œë”© ì‹œê°„ (ì´ˆ)
    
    # ìºì‹œ ì›Œë°ì—…
    enable_cache_warmup: bool = True
    cache_warmup_functions: List[Callable] = field(default_factory=list)
    max_warmup_time: float = 3.0  # ìµœëŒ€ ì›Œë°ì—… ì‹œê°„ (ì´ˆ)
    
    # ë©”ëª¨ë¦¬ ìµœì í™”
    enable_gc_optimization: bool = True
    gc_freeze: bool = True  # GC freezeë¡œ ì„±ëŠ¥ í–¥ìƒ
    memory_threshold_mb: float = 100.0  # ë©”ëª¨ë¦¬ ì„ê³„ê°’
    
    # ë™ì‹œì„± ì„¤ì •
    max_workers: int = 4  # ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
    enable_async_warmup: bool = True
    
    # ëª¨ë‹ˆí„°ë§
    collect_detailed_metrics: bool = True
    log_optimization_steps: bool = True


class ColdStartOptimizer:
    """
    Cold Start ìµœì í™” í•µì‹¬ í´ë˜ìŠ¤
    
    ì‚¬ìš©ë²•:
        optimizer = ColdStartOptimizer()
        optimizer.preload_modules(['numpy', 'pandas'])
        await optimizer.warm_up()
        metrics = optimizer.get_metrics()
    """
    
    def __init__(self, config: OptimizationConfig = None):
        self.config = config or OptimizationConfig()
        self.start_time = time.time()
        self.metrics = StartupMetrics()
        
        # ìƒíƒœ ì¶”ì 
        self._preloaded_modules: Set[str] = set()
        self._warmup_functions: List[Callable] = []
        self._optimization_completed = False
        
        # ì„±ëŠ¥ ì¶”ì 
        self._phase_times: Dict[str, float] = {}
        self._import_times: Dict[str, float] = {}
        
        # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        self.metrics.initial_memory_mb = self._get_memory_usage()
        
        if self.config.log_optimization_steps:
            logger.info(f"ColdStartOptimizer initialized with {self.config.level.value} optimization level")
    
    def preload_modules(self, modules: List[str], timeout: float = None) -> Dict[str, bool]:
        """
        ëª¨ë“ˆë“¤ì„ ì‚¬ì „ ë¡œë”©
        
        Args:
            modules: ë¡œë”©í•  ëª¨ë“ˆ ëª©ë¡
            timeout: ë¡œë”© íƒ€ì„ì•„ì›ƒ (ì´ˆ)
            
        Returns:
            Dict[str, bool]: ëª¨ë“ˆë³„ ë¡œë”© ì„±ê³µ ì—¬ë¶€
        """
        phase_start = time.time()
        timeout = timeout or self.config.max_preload_time
        
        results = {}
        failed_count = 0
        
        if self.config.level == OptimizationLevel.AGGRESSIVE and self.config.max_workers > 1:
            # ë³‘ë ¬ ë¡œë”©
            results = self._parallel_module_loading(modules, timeout)
            failed_count = sum(1 for success in results.values() if not success)
        else:
            # ìˆœì°¨ ë¡œë”©
            for module_name in modules:
                start_time = time.time()
                try:
                    importlib.import_module(module_name)
                    self._preloaded_modules.add(module_name)
                    results[module_name] = True
                    
                    import_time = time.time() - start_time
                    self._import_times[module_name] = import_time
                    
                    if self.config.log_optimization_steps:
                        logger.debug(f"Preloaded {module_name} in {import_time:.3f}s")
                
                except ImportError as e:
                    results[module_name] = False
                    failed_count += 1
                    if self.config.log_optimization_steps:
                        logger.warning(f"Failed to preload {module_name}: {e}")
                
                except Exception as e:
                    results[module_name] = False
                    failed_count += 1
                    logger.error(f"Error preloading {module_name}: {e}")
                
                # íƒ€ì„ì•„ì›ƒ ì²´í¬
                if time.time() - phase_start > timeout:
                    logger.warning(f"Module preloading timeout after {timeout}s")
                    break
        
        phase_time = time.time() - phase_start
        self._phase_times['preload'] = phase_time
        self.metrics.import_time = phase_time
        self.metrics.preloaded_modules = len(self._preloaded_modules)
        self.metrics.failed_imports = failed_count
        
        if self.config.log_optimization_steps:
            logger.info(f"Preloaded {len(self._preloaded_modules)} modules in {phase_time:.3f}s")
        
        return results
    
    def _parallel_module_loading(self, modules: List[str], timeout: float) -> Dict[str, bool]:
        """ë³‘ë ¬ ëª¨ë“ˆ ë¡œë”©"""
        results = {}
        
        def load_module(module_name: str) -> tuple[str, bool, float]:
            start_time = time.time()
            try:
                importlib.import_module(module_name)
                load_time = time.time() - start_time
                return module_name, True, load_time
            except Exception:
                load_time = time.time() - start_time
                return module_name, False, load_time
        
        with ThreadPoolExecutor(max_workers=self.config.max_workers) as executor:
            # ëª¨ë“  ëª¨ë“ˆ ë¡œë”© ì‘ì—… ì œì¶œ
            future_to_module = {
                executor.submit(load_module, module): module 
                for module in modules
            }
            
            # ê²°ê³¼ ìˆ˜ì§‘ (íƒ€ì„ì•„ì›ƒ í¬í•¨)
            for future in as_completed(future_to_module, timeout=timeout):
                try:
                    module_name, success, load_time = future.result()
                    results[module_name] = success
                    self._import_times[module_name] = load_time
                    
                    if success:
                        self._preloaded_modules.add(module_name)
                
                except Exception as e:
                    module_name = future_to_module[future]
                    results[module_name] = False
                    logger.error(f"Parallel loading error for {module_name}: {e}")
        
        return results
    
    def register_warmup_function(self, func: Callable, priority: int = 0) -> None:
        """
        ì›Œë°ì—… í•¨ìˆ˜ ë“±ë¡
        
        Args:
            func: ì›Œë°ì—… í•¨ìˆ˜
            priority: ìš°ì„ ìˆœìœ„ (ë‚®ì„ìˆ˜ë¡ ë¨¼ì € ì‹¤í–‰)
        """
        self._warmup_functions.append((priority, func))
        # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
        self._warmup_functions.sort(key=lambda x: x[0])
    
    async def warm_up(self, timeout: float = None) -> Dict[str, Any]:
        """
        ìºì‹œ ë° ì—°ê²° ì›Œë°ì—…
        
        Args:
            timeout: ì›Œë°ì—… íƒ€ì„ì•„ì›ƒ (ì´ˆ)
            
        Returns:
            Dict[str, Any]: ì›Œë°ì—… ê²°ê³¼
        """
        if not self.config.enable_cache_warmup:
            return {"skipped": True, "reason": "cache warmup disabled"}
        
        phase_start = time.time()
        timeout = timeout or self.config.max_warmup_time
        
        results = {
            "successful": 0,
            "failed": 0,
            "total_time": 0.0,
            "function_results": {}
        }
        
        # ë“±ë¡ëœ ì›Œë°ì—… í•¨ìˆ˜ë“¤ ì‹¤í–‰
        warmup_functions = self._warmup_functions + [(999, func) for func in self.config.cache_warmup_functions]
        
        if self.config.enable_async_warmup:
            results = await self._async_warmup(warmup_functions, timeout)
        else:
            results = await self._sync_warmup(warmup_functions, timeout)
        
        phase_time = time.time() - phase_start
        self._phase_times['warmup'] = phase_time
        self.metrics.warmup_time = phase_time
        results["total_time"] = phase_time
        
        if self.config.log_optimization_steps:
            logger.info(f"Warmup completed in {phase_time:.3f}s: {results['successful']} success, {results['failed']} failed")
        
        return results
    
    async def _async_warmup(self, warmup_functions: List[tuple], timeout: float) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ì›Œë°ì—… ì‹¤í–‰"""
        results = {"successful": 0, "failed": 0, "function_results": {}}
        
        async def execute_warmup(priority_func_tuple):
            priority, func = priority_func_tuple
            func_name = getattr(func, '__name__', str(func))
            
            try:
                start_time = time.time()
                
                if asyncio.iscoroutinefunction(func):
                    result = await func()
                else:
                    result = func()
                
                exec_time = time.time() - start_time
                results["function_results"][func_name] = {
                    "success": True,
                    "result": result,
                    "execution_time": exec_time
                }
                results["successful"] += 1
                
            except Exception as e:
                exec_time = time.time() - start_time
                results["function_results"][func_name] = {
                    "success": False,
                    "error": str(e),
                    "execution_time": exec_time
                }
                results["failed"] += 1
                
                if self.config.log_optimization_steps:
                    logger.warning(f"Warmup function {func_name} failed: {e}")
        
        # ëª¨ë“  ì›Œë°ì—… í•¨ìˆ˜ ë¹„ë™ê¸° ì‹¤í–‰
        tasks = [execute_warmup(pf) for pf in warmup_functions]
        
        try:
            await asyncio.wait_for(asyncio.gather(*tasks, return_exceptions=True), timeout=timeout)
        except asyncio.TimeoutError:
            logger.warning(f"Warmup timeout after {timeout}s")
        
        return results
    
    async def _sync_warmup(self, warmup_functions: List[tuple], timeout: float) -> Dict[str, Any]:
        """ë™ê¸° ì›Œë°ì—… ì‹¤í–‰"""
        results = {"successful": 0, "failed": 0, "function_results": {}}
        start_time = time.time()
        
        for priority, func in warmup_functions:
            if time.time() - start_time > timeout:
                logger.warning(f"Warmup timeout after {timeout}s")
                break
            
            func_name = getattr(func, '__name__', str(func))
            
            try:
                func_start = time.time()
                
                if asyncio.iscoroutinefunction(func):
                    result = await func()
                else:
                    result = func()
                
                exec_time = time.time() - func_start
                results["function_results"][func_name] = {
                    "success": True,
                    "result": result,
                    "execution_time": exec_time
                }
                results["successful"] += 1
                
            except Exception as e:
                exec_time = time.time() - func_start
                results["function_results"][func_name] = {
                    "success": False,
                    "error": str(e),
                    "execution_time": exec_time
                }
                results["failed"] += 1
                
                if self.config.log_optimization_steps:
                    logger.warning(f"Warmup function {func_name} failed: {e}")
        
        return results
    
    def optimize_memory(self) -> Dict[str, Any]:
        """
        ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì í™”
        
        Returns:
            Dict[str, Any]: ë©”ëª¨ë¦¬ ìµœì í™” ê²°ê³¼
        """
        if not self.config.enable_gc_optimization:
            return {"skipped": True, "reason": "gc optimization disabled"}
        
        phase_start = time.time()
        initial_memory = self._get_memory_usage()
        
        optimization_results = {
            "initial_memory_mb": initial_memory,
            "final_memory_mb": 0.0,
            "memory_freed_mb": 0.0,
            "gc_collections": 0,
            "optimization_time": 0.0
        }
        
        try:
            # 1. ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            collected_objects = []
            for generation in range(3):
                collected = gc.collect()
                collected_objects.append(collected)
                optimization_results["gc_collections"] += collected
            
            # 2. GC í†µê³„ í™•ì¸
            gc_stats = gc.get_stats()
            if self.config.collect_detailed_metrics:
                optimization_results["gc_stats"] = gc_stats
            
            # 3. GC freeze (ì„±ëŠ¥ í–¥ìƒ)
            if self.config.gc_freeze and hasattr(gc, 'freeze'):
                gc.freeze()
                optimization_results["gc_frozen"] = True
            
            # 4. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¬ì¸¡ì •
            final_memory = self._get_memory_usage()
            optimization_results["final_memory_mb"] = final_memory
            optimization_results["memory_freed_mb"] = max(0, initial_memory - final_memory)
            
            # 5. GC ì„ê³„ê°’ ì¡°ì • (aggressive ëª¨ë“œ)
            if self.config.level == OptimizationLevel.AGGRESSIVE:
                # GC ì„ê³„ê°’ì„ ëŠ˜ë ¤ì„œ ë¹ˆë„ ì¤„ì´ê¸°
                original_thresholds = gc.get_threshold()
                new_thresholds = (original_thresholds[0] * 2, 
                                original_thresholds[1] * 2, 
                                original_thresholds[2] * 2)
                gc.set_threshold(*new_thresholds)
                optimization_results["gc_thresholds"] = {
                    "original": original_thresholds,
                    "new": new_thresholds
                }
        
        except Exception as e:
            optimization_results["error"] = str(e)
            logger.error(f"Memory optimization error: {e}")
        
        phase_time = time.time() - phase_start
        optimization_results["optimization_time"] = phase_time
        self._phase_times['memory_optimization'] = phase_time
        self.metrics.gc_time = phase_time
        self.metrics.memory_saved_mb = optimization_results["memory_freed_mb"]
        
        if self.config.log_optimization_steps:
            logger.info(f"Memory optimization completed in {phase_time:.3f}s, freed {optimization_results['memory_freed_mb']:.1f}MB")
        
        return optimization_results
    
    def _get_memory_usage(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ (MB)"""
        try:
            process = psutil.Process()
            return process.memory_info().rss / (1024 * 1024)
        except Exception:
            return 0.0
    
    def get_metrics(self) -> StartupMetrics:
        """ì‹œì‘ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        if not self._optimization_completed:
            self._finalize_metrics()
        
        return self.metrics
    
    def _finalize_metrics(self):
        """ë©”íŠ¸ë¦­ ìµœì¢…í™”"""
        self.metrics.total_startup_time = time.time() - self.start_time
        self.metrics.final_memory_mb = self._get_memory_usage()
        
        # ì´ˆê¸°í™” ì‹œê°„ ê³„ì‚° (ì „ì²´ - ëª…ì‹œì  ë‹¨ê³„ë“¤)
        explicit_time = (self.metrics.import_time + 
                        self.metrics.warmup_time + 
                        self.metrics.gc_time)
        self.metrics.initialization_time = max(0, self.metrics.total_startup_time - explicit_time)
        
        self._optimization_completed = True
    
    def get_detailed_report(self) -> Dict[str, Any]:
        """ìƒì„¸ ìµœì í™” ë³´ê³ ì„œ"""
        metrics = self.get_metrics()
        
        report = {
            "optimization_config": {
                "level": self.config.level.value,
                "max_preload_time": self.config.max_preload_time,
                "max_warmup_time": self.config.max_warmup_time,
                "max_workers": self.config.max_workers,
            },
            "startup_metrics": {
                "total_startup_time": metrics.total_startup_time,
                "import_time": metrics.import_time,
                "initialization_time": metrics.initialization_time,
                "warmup_time": metrics.warmup_time,
                "gc_time": metrics.gc_time,
            },
            "module_metrics": {
                "preloaded_modules": metrics.preloaded_modules,
                "failed_imports": metrics.failed_imports,
                "import_details": self._import_times.copy(),
            },
            "memory_metrics": {
                "initial_memory_mb": metrics.initial_memory_mb,
                "final_memory_mb": metrics.final_memory_mb,
                "memory_saved_mb": metrics.memory_saved_mb,
                "available_memory_mb": metrics.available_memory_mb,
            },
            "system_info": {
                "cpu_cores": metrics.cpu_cores,
                "python_version": metrics.python_version,
            },
            "phase_times": self._phase_times.copy(),
            "recommendations": self._generate_recommendations()
        }
        
        return report
    
    def _generate_recommendations(self) -> List[str]:
        """ì„±ëŠ¥ ê°œì„  ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        metrics = self.get_metrics()
        
        # ì‹œì‘ ì‹œê°„ ê¸°ë°˜ ì¶”ì²œ
        if metrics.total_startup_time > 5.0:
            recommendations.append("Consider reducing the number of preloaded modules")
        
        # ë©”ëª¨ë¦¬ ê¸°ë°˜ ì¶”ì²œ
        if metrics.final_memory_mb > 200:
            recommendations.append("Consider enabling more aggressive memory optimization")
        
        # Import ì‹œê°„ ê¸°ë°˜ ì¶”ì²œ
        if metrics.import_time > 3.0:
            recommendations.append("Consider async module loading or reducing module dependencies")
        
        # ì‹¤íŒ¨ìœ¨ ê¸°ë°˜ ì¶”ì²œ
        if metrics.failed_imports > 0:
            recommendations.append("Review and update the list of preloaded modules")
        
        # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ê¸°ë°˜ ì¶”ì²œ
        if metrics.cpu_cores > 2 and self.config.max_workers < metrics.cpu_cores:
            recommendations.append(f"Consider increasing max_workers to {metrics.cpu_cores} for better parallel performance")
        
        return recommendations
    
    def export_metrics_json(self) -> str:
        """ë©”íŠ¸ë¦­ì„ JSONìœ¼ë¡œ export"""
        import json
        report = self.get_detailed_report()
        return json.dumps(report, indent=2, default=str)


# í¸ì˜ í•¨ìˆ˜ë“¤
def create_optimizer(level: OptimizationLevel = OptimizationLevel.MODERATE,
                    modules: List[str] = None,
                    warmup_functions: List[Callable] = None) -> ColdStartOptimizer:
    """
    Cold Start Optimizer ìƒì„± í¸ì˜ í•¨ìˆ˜
    
    Args:
        level: ìµœì í™” ìˆ˜ì¤€
        modules: ì‚¬ì „ ë¡œë”©í•  ëª¨ë“ˆë“¤
        warmup_functions: ì›Œë°ì—… í•¨ìˆ˜ë“¤
        
    Returns:
        ColdStartOptimizer: ì„¤ì •ëœ ì˜µí‹°ë§ˆì´ì €
    """
    config = OptimizationConfig(
        level=level,
        preload_modules=modules or [],
        cache_warmup_functions=warmup_functions or []
    )
    
    return ColdStartOptimizer(config)


async def quick_optimize(modules: List[str] = None,
                        warmup_functions: List[Callable] = None,
                        level: OptimizationLevel = OptimizationLevel.MODERATE) -> StartupMetrics:
    """
    ë¹ ë¥¸ ìµœì í™” ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        modules: ì‚¬ì „ ë¡œë”©í•  ëª¨ë“ˆë“¤
        warmup_functions: ì›Œë°ì—… í•¨ìˆ˜ë“¤
        level: ìµœì í™” ìˆ˜ì¤€
        
    Returns:
        StartupMetrics: ìµœì í™” ê²°ê³¼ ë©”íŠ¸ë¦­
    """
    optimizer = create_optimizer(level, modules, warmup_functions)
    
    # ëª¨ë“ˆ ì‚¬ì „ ë¡œë”©
    if modules:
        optimizer.preload_modules(modules)
    
    # ì›Œë°ì—… ì‹¤í–‰
    await optimizer.warm_up()
    
    # ë©”ëª¨ë¦¬ ìµœì í™”
    optimizer.optimize_memory()
    
    return optimizer.get_metrics()


# ì˜ˆì œ ë° í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    async def example_usage():
        """ì‚¬ìš© ì˜ˆì œ"""
        print("ğŸš€ RFS Cold Start Optimizer Example")
        
        # 1. ê¸°ë³¸ ì‚¬ìš©ë²•
        optimizer = ColdStartOptimizer()
        
        # 2. ëª¨ë“ˆ ì‚¬ì „ ë¡œë”©
        common_modules = ['json', 'datetime', 'uuid', 'logging']
        results = optimizer.preload_modules(common_modules)
        print(f"Preloaded modules: {sum(results.values())}/{len(results)}")
        
        # 3. ì›Œë°ì—… í•¨ìˆ˜ ë“±ë¡
        def cache_warmup():
            """ìºì‹œ ì›Œë°ì—… ì˜ˆì œ"""
            return {"cache": "warmed"}
        
        async def async_warmup():
            """ë¹„ë™ê¸° ì›Œë°ì—… ì˜ˆì œ"""
            await asyncio.sleep(0.1)  # ë¹„ë™ê¸° ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
            return {"async_cache": "warmed"}
        
        optimizer.register_warmup_function(cache_warmup)
        optimizer.register_warmup_function(async_warmup)
        
        # 4. ì›Œë°ì—… ì‹¤í–‰
        warmup_results = await optimizer.warm_up()
        print(f"Warmup completed: {warmup_results['successful']} successful")
        
        # 5. ë©”ëª¨ë¦¬ ìµœì í™”
        memory_results = optimizer.optimize_memory()
        print(f"Memory optimized: freed {memory_results.get('memory_freed_mb', 0):.1f}MB")
        
        # 6. ë©”íŠ¸ë¦­ ì¡°íšŒ
        metrics = optimizer.get_metrics()
        print(f"Total startup time: {metrics.total_startup_time:.3f}s")
        print(f"Import time: {metrics.import_time:.3f}s")
        print(f"Warmup time: {metrics.warmup_time:.3f}s")
        print(f"Memory usage: {metrics.final_memory_mb:.1f}MB")
        
        # 7. ìƒì„¸ ë³´ê³ ì„œ
        report = optimizer.get_detailed_report()
        print(f"\nRecommendations:")
        for rec in report["recommendations"]:
            print(f"  - {rec}")
        
        # 8. ë¹ ë¥¸ ìµœì í™” ì˜ˆì œ
        print("\nğŸƒ Quick optimization example:")
        quick_metrics = await quick_optimize(
            modules=['os', 'sys', 'time'],
            level=OptimizationLevel.AGGRESSIVE
        )
        print(f"Quick optimization completed in {quick_metrics.total_startup_time:.3f}s")
    
    asyncio.run(example_usage())