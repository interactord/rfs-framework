# RFS Framework v4.2 ì‚¬ìš©ì ê°€ì´ë“œ

## ì†Œê°œ

RFS Framework v4.2ëŠ” ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ Python ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ì¢…í•©ì ì¸ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì„±ëŠ¥ ìµœì í™”, í”„ë¡œë•ì…˜ ê´€ë¦¬, ê·¸ë¦¬ê³  ê³ ê¸‰ í†µí•© ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•

- âš¡ **ì„±ëŠ¥ ìµœì í™”**: ì‹¤ì‹œê°„ í”„ë¡œíŒŒì¼ë§ ë° ìë™ ìµœì í™”
- ğŸ” **í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§**: 24/7 ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼
- ğŸ”„ **ì¬í•´ ë³µêµ¬**: ìë™ ë°±ì—… ë° ë³µêµ¬ ì‹œìŠ¤í…œ
- ğŸŒ **API Gateway**: ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ API ê´€ë¦¬
- ğŸ’¾ **ë¶„ì‚° ìºì‹œ**: ê³ ì„±ëŠ¥ ë©€í‹°ë ˆë²¨ ìºì‹±
- ğŸ”Œ **ì›¹ í†µí•©**: REST, GraphQL, WebSocket ì§€ì›

## ë¹ ë¥¸ ì‹œì‘

### ì„¤ì¹˜

```bash
# ì „ì²´ ê¸°ëŠ¥ ì„¤ì¹˜
pip install rfs-framework[all]

# íŠ¹ì • ê¸°ëŠ¥ë§Œ ì„¤ì¹˜
pip install rfs-framework[performance,production,integration]
```

### ê¸°ë³¸ ì„¤ì •

```python
# config.py
from rfs.config import RFSConfig

config = RFSConfig(
    environment="production",
    cloud_run_enabled=True,
    monitoring_enabled=True,
    cache_backend="redis",
    api_gateway_enabled=True
)
```

## ì‚¬ìš© ì˜ˆì œ

### 1. ì„±ëŠ¥ ìµœì í™”

#### ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë¡œíŒŒì¼ë§

```python
import asyncio
from rfs.performance.profiling import get_system_profiler

async def profile_application():
    profiler = get_system_profiler()
    await profiler.start()
    
    # í”„ë¡œíŒŒì¼ë§í•  ì‘ì—…
    await profiler.start_profile("data_processing")
    
    # ì‹¤ì œ ì‘ì—… ìˆ˜í–‰
    data = await process_large_dataset()
    
    # í”„ë¡œíŒŒì¼ ê²°ê³¼ í™•ì¸
    result = await profiler.stop_profile("data_processing")
    profile = result.value
    
    print(f"ì‘ì—… ì‹œê°„: {profile.duration}ì´ˆ")
    print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©: {profile.memory_used / 1024 / 1024:.2f} MB")
    print(f"CPU ì‚¬ìš©ë¥ : {profile.cpu_usage}%")
    
    # ë³‘ëª© í˜„ìƒ ë¶„ì„
    bottlenecks = profile.bottlenecks
    for bottleneck in bottlenecks:
        print(f"ë³‘ëª©: {bottleneck.function_name} - {bottleneck.time_spent}ì´ˆ")
    
    await profiler.stop()

asyncio.run(profile_application())
```

#### Cloud Run ìµœì í™”

```python
from rfs.performance.optimization import get_cloud_run_optimizer

async def optimize_for_cloud_run():
    optimizer = get_cloud_run_optimizer()
    
    # í™˜ê²½ ë¶„ì„ ë° ìµœì í™”
    recommendations = await optimizer.optimize()
    
    print("ì¶”ì²œ ì„¤ì •:")
    print(f"- ë™ì‹œ ì‹¤í–‰: {recommendations.value['concurrency']}")
    print(f"- ë©”ëª¨ë¦¬: {recommendations.value['memory']} MB")
    print(f"- CPU: {recommendations.value['cpu']}")
    
    # ìë™ ìŠ¤ì¼€ì¼ë§ ì„¤ì •
    await optimizer.configure_autoscaling(
        min_instances=1,
        max_instances=100,
        target_cpu_utilization=70
    )

asyncio.run(optimize_for_cloud_run())
```

### 2. í”„ë¡œë•ì…˜ ê´€ë¦¬

#### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

```python
from rfs.production.monitoring import get_production_monitor, get_alert_manager

async def setup_monitoring():
    monitor = get_production_monitor()
    alert_manager = get_alert_manager()
    
    await monitor.start()
    await alert_manager.start()
    
    # ì•Œë¦¼ ê·œì¹™ ì„¤ì •
    alert_manager.add_rule(
        rule_id="high_cpu",
        name="CPU ì‚¬ìš©ëŸ‰ ë†’ìŒ",
        condition="cpu_percent > 80",
        level="WARNING",
        channels=["email", "slack"]
    )
    
    alert_manager.add_rule(
        rule_id="low_memory",
        name="ë©”ëª¨ë¦¬ ë¶€ì¡±",
        condition="memory_available < 100",  # MB
        level="CRITICAL",
        channels=["email", "slack", "pagerduty"]
    )
    
    # ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
    while True:
        metrics = monitor.get_current_metrics()
        
        print(f"CPU: {metrics['system']['cpu_percent']}%")
        print(f"ë©”ëª¨ë¦¬: {metrics['system']['memory_percent']}%")
        print(f"ë””ìŠ¤í¬: {metrics['system']['disk_percent']}%")
        
        await asyncio.sleep(60)  # 1ë¶„ë§ˆë‹¤ í™•ì¸

asyncio.run(setup_monitoring())
```

#### ë°±ì—… ë° ë³µêµ¬

```python
from rfs.production.recovery import (
    get_backup_manager,
    BackupPolicy,
    BackupTarget,
    BackupType
)

async def setup_backup_system():
    backup_manager = get_backup_manager()
    await backup_manager.start()
    
    # ë°±ì—… ì •ì±… ì„¤ì •
    policy = BackupPolicy(
        id="daily_backup",
        name="ì¼ì¼ ë°±ì—…",
        backup_type=BackupType.INCREMENTAL,
        schedule="0 2 * * *",  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ
        retention_days=30
    )
    
    backup_manager.add_policy(policy)
    
    # ë°±ì—… ëŒ€ìƒ ì„¤ì •
    target = BackupTarget(
        id="database",
        name="ë°ì´í„°ë² ì´ìŠ¤",
        type="database",
        source_path="postgresql://localhost/mydb"
    )
    
    backup_manager.add_target(target)
    
    # ìˆ˜ë™ ë°±ì—… ì‹¤í–‰
    backup_operation = await backup_manager.create_backup(
        policy_id="daily_backup",
        target_id="database",
        manual=True
    )
    
    print(f"ë°±ì—… ì‹œì‘: {backup_operation.value.id}")

asyncio.run(setup_backup_system())
```

### 3. API Gateway êµ¬ì„±

```python
from rfs.integration import (
    get_api_gateway,
    Route,
    Backend,
    LoadBalanceStrategy
)

async def setup_api_gateway():
    gateway = get_api_gateway()
    await gateway.start()
    
    # ë°±ì—”ë“œ ì„œë²„ ì„¤ì •
    backends = [
        Backend("server1", "10.0.1.10", 8080, weight=2),
        Backend("server2", "10.0.1.11", 8080, weight=1),
        Backend("server3", "10.0.1.12", 8080, weight=1)
    ]
    
    # API ë¼ìš°íŠ¸ ì„¤ì •
    user_route = Route(
        id="user_api",
        path="/api/v1/users",
        methods=["GET", "POST", "PUT", "DELETE"],
        backends=backends,
        authentication="JWT",
        rate_limit={
            "requests_per_second": 100,
            "burst_size": 200
        },
        cache_config={
            "ttl": 60,
            "key_pattern": "user_{id}"
        }
    )
    
    gateway.add_route(user_route)
    
    # ë¡œë“œ ë°¸ëŸ°ì‹± ì „ëµ ì„¤ì •
    gateway.load_balancer.strategy = LoadBalanceStrategy.LEAST_CONNECTIONS
    
    print("API Gatewayê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")

asyncio.run(setup_api_gateway())
```

### 4. ë¶„ì‚° ìºì‹œ ì‚¬ìš©

```python
from rfs.integration import (
    get_distributed_cache_manager,
    CacheConfig,
    CacheBackend,
    EvictionPolicy
)

async def use_distributed_cache():
    # Redis ë°±ì—”ë“œ ìºì‹œ ì„¤ì •
    config = CacheConfig(
        backend=CacheBackend.REDIS,
        eviction_policy=EvictionPolicy.LRU,
        max_size=100000,
        max_memory_mb=512,
        default_ttl=3600
    )
    
    cache = get_distributed_cache_manager(config)
    await cache.start()
    
    # ë°ì´í„° ìºì‹±
    user_data = {
        "id": "123",
        "name": "John Doe",
        "email": "john@example.com"
    }
    
    await cache.set("user:123", user_data, ttl=1800)
    
    # ìºì‹œ ì¡°íšŒ
    result = await cache.get("user:123")
    if result.value:
        print(f"ìºì‹œì—ì„œ ì¡°íšŒ: {result.value}")
    
    # ìºì‹œ íŒŒí‹°ì…˜ ì‚¬ìš©
    cache.create_partition(
        "session_cache",
        "ì„¸ì…˜ ìºì‹œ",
        CacheConfig(
            backend=CacheBackend.MEMORY,
            max_size=1000,
            default_ttl=900  # 15ë¶„
        )
    )
    
    # ì„¸ì…˜ ë°ì´í„° ì €ì¥
    await cache.set(
        "session:abc123",
        {"user_id": "123", "login_time": "2025-01-01T10:00:00"},
        partition_id="session_cache"
    )

asyncio.run(use_distributed_cache())
```

## ê³ ê¸‰ ê¸°ëŠ¥

### í†µí•© ì›Œí¬í”Œë¡œìš°

```python
import asyncio
from rfs.performance import get_system_profiler, get_cloud_run_optimizer
from rfs.production import get_production_monitor, get_alert_manager
from rfs.integration import get_api_gateway, get_distributed_cache_manager

async def integrated_application():
    # 1. í”„ë¡œíŒŒì¼ë§ ì‹œì‘
    profiler = get_system_profiler()
    await profiler.start()
    
    # 2. ëª¨ë‹ˆí„°ë§ ì‹œì‘
    monitor = get_production_monitor()
    alert_manager = get_alert_manager()
    await monitor.start()
    await alert_manager.start()
    
    # 3. ìºì‹œ ì´ˆê¸°í™”
    cache = get_distributed_cache_manager()
    await cache.start()
    
    # 4. API Gateway ì‹œì‘
    gateway = get_api_gateway()
    await gateway.start()
    
    # 5. ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§
    async def handle_request(request):
        # ìºì‹œ í™•ì¸
        cached = await cache.get(f"request:{request.id}")
        if cached.value:
            return cached.value
        
        # í”„ë¡œíŒŒì¼ë§
        await profiler.start_profile(f"request_{request.id}")
        
        # ì‹¤ì œ ì²˜ë¦¬
        result = await process_request(request)
        
        # í”„ë¡œíŒŒì¼ ì¢…ë£Œ
        profile = await profiler.stop_profile(f"request_{request.id}")
        
        # ì„±ëŠ¥ì´ ë‚˜ì˜ë©´ ì•Œë¦¼
        if profile.value.duration > 1.0:  # 1ì´ˆ ì´ìƒ
            await alert_manager.create_alert(
                rule_id="slow_request",
                title="ëŠë¦° ìš”ì²­ ê°ì§€",
                message=f"ìš”ì²­ {request.id}ê°€ {profile.value.duration}ì´ˆ ê±¸ë¦¼"
            )
        
        # ê²°ê³¼ ìºì‹±
        await cache.set(f"request:{request.id}", result, ttl=300)
        
        return result
    
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
    while True:
        # ìš”ì²­ ì²˜ë¦¬
        request = await get_next_request()
        result = await handle_request(request)
        await send_response(result)

asyncio.run(integrated_application())
```

## ëª¨ë²” ì‚¬ë¡€

### 1. ì—ëŸ¬ ì²˜ë¦¬

```python
from rfs.core import Success, Failure

async def safe_operation():
    result = await some_api_call()
    
    if isinstance(result, Success):
        # ì„±ê³µ ì²˜ë¦¬
        data = result.value
        return process_data(data)
    else:
        # ì‹¤íŒ¨ ì²˜ë¦¬
        error = result.error
        logger.error(f"ì‘ì—… ì‹¤íŒ¨: {error}")
        
        # ì¬ì‹œë„ ë¡œì§
        for attempt in range(3):
            retry_result = await some_api_call()
            if isinstance(retry_result, Success):
                return retry_result.value
            await asyncio.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
        return None
```

### 2. ë¦¬ì†ŒìŠ¤ ì •ë¦¬

```python
async def managed_resources():
    monitor = get_production_monitor()
    cache = get_distributed_cache_manager()
    
    try:
        # ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”
        await monitor.start()
        await cache.start()
        
        # ì‘ì—… ìˆ˜í–‰
        await do_work()
        
    finally:
        # í•­ìƒ ì •ë¦¬
        await monitor.stop()
        await cache.stop()
```

### 3. ì„±ëŠ¥ ìµœì í™” íŒ

1. **ìºì‹± ì ê·¹ í™œìš©**: ìì£¼ ì ‘ê·¼í•˜ëŠ” ë°ì´í„°ëŠ” í•­ìƒ ìºì‹œ
2. **ë¹„ë™ê¸° ì²˜ë¦¬**: I/O ì‘ì—…ì€ í•­ìƒ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
3. **ë°°ì¹˜ ì²˜ë¦¬**: ê°€ëŠ¥í•œ ê²½ìš° ìš”ì²­ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬
4. **ì—°ê²° í’€ë§**: ë°ì´í„°ë² ì´ìŠ¤ì™€ ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ê²°ì€ í’€ë§ ì‚¬ìš©
5. **í”„ë¡œíŒŒì¼ë§**: ì •ê¸°ì ìœ¼ë¡œ í”„ë¡œíŒŒì¼ë§í•˜ì—¬ ë³‘ëª© í˜„ìƒ íŒŒì•…

### 4. í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ëª¨ë‹ˆí„°ë§ ì„¤ì • ì™„ë£Œ
- [ ] ì•Œë¦¼ ê·œì¹™ êµ¬ì„±
- [ ] ë°±ì—… ì •ì±… ì„¤ì •
- [ ] ì¬í•´ ë³µêµ¬ ê³„íš ìˆ˜ë¦½
- [ ] ì»´í”Œë¼ì´ì–¸ìŠ¤ ê²€ì¦
- [ ] API ì†ë„ ì œí•œ ì„¤ì •
- [ ] ìºì‹œ ì „ëµ ìˆ˜ë¦½
- [ ] ë¡œë“œ ë°¸ëŸ°ì‹± êµ¬ì„±
- [ ] í—¬ìŠ¤ ì²´í¬ ì„¤ì •
- [ ] ë¡œê¹… êµ¬ì„±

## ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

#### 1. ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©

```python
from rfs.performance.optimization import get_memory_optimizer

async def fix_memory_issues():
    optimizer = get_memory_optimizer()
    
    # ë©”ëª¨ë¦¬ ë¶„ì„
    analysis = await optimizer.analyze()
    
    # ìë™ ìµœì í™”
    await optimizer.optimize(strategy="AGGRESSIVE")
    
    # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ
    await optimizer.force_garbage_collection()
```

#### 2. ëŠë¦° API ì‘ë‹µ

```python
# 1. í”„ë¡œíŒŒì¼ë§ìœ¼ë¡œ ë³‘ëª© í™•ì¸
profile = await profiler.profile_endpoint("/api/slow")

# 2. ìºì‹œ ì¶”ê°€
await cache.set(cache_key, response_data, ttl=300)

# 3. ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”
# 4. ë¹„ë™ê¸° ì²˜ë¦¬ ì¶”ê°€
```

#### 3. ìºì‹œ ë¯¸ìŠ¤ìœ¨ ë†’ìŒ

```python
# ìºì‹œ í†µê³„ í™•ì¸
stats = cache.get_statistics()
print(f"íˆíŠ¸ìœ¨: {stats.hit_ratio}%")

# ìºì‹œ ì›Œë°
await cache.add_warmup_task(
    task_id="popular_data",
    loader=load_popular_data,
    keys=popular_keys,
    schedule="startup"
)
```

## ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [API ë ˆí¼ëŸ°ìŠ¤](API_REFERENCE.md)
- [ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ](./MIGRATION_GUIDE.md)
- [ë³€ê²½ ë¡œê·¸](changelog.md)
- [GitHub ì €ì¥ì†Œ](https://github.com/your-org/rfs-framework)

## ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ë„ì›€ì´ í•„ìš”í•œ ê²½ìš°:

1. [ì´ìŠˆ íŠ¸ë˜ì»¤](https://github.com/your-org/rfs-framework/issues)ì— ë¬¸ì œ ì œì¶œ
2. [í† ë¡  í¬ëŸ¼](https://github.com/your-org/rfs-framework/discussions) ì°¸ì—¬
3. [ê³µì‹ ë¬¸ì„œ](https://rfs-framework.readthedocs.io) í™•ì¸

## ë¼ì´ì„ ìŠ¤

RFS FrameworkëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.