# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (Performance Monitoring)

## ğŸ“Œ ê°œìš”

RFS Frameworkì˜ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì€ ë©”íŠ¸ë¦­ìŠ¤ ìˆ˜ì§‘, ì„±ëŠ¥ ì¸¡ì •, ì•Œë¦¼ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. Prometheusì™€ í˜¸í™˜ë˜ë©° ì‹¤ì‹œê°„ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ í•µì‹¬ ê°œë…

### ë©”íŠ¸ë¦­ ìœ í˜•
- **Counter**: ë‹¨ì¡° ì¦ê°€í•˜ëŠ” ëˆ„ì  ë©”íŠ¸ë¦­ (ìš”ì²­ ìˆ˜, ì—ëŸ¬ ìˆ˜)
- **Gauge**: ì¦ê°€/ê°ì†Œ ê°€ëŠ¥í•œ ìˆœê°„ê°’ (ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, ì—°ê²° ìˆ˜)
- **Histogram**: ë¶„í¬ë¥¼ ì¸¡ì •í•˜ëŠ” ë©”íŠ¸ë¦­ (ì‘ë‹µ ì‹œê°„ ë¶„í¬)
- **Summary**: ë¶„ìœ„ìˆ˜ë¥¼ ì œê³µí•˜ëŠ” ë©”íŠ¸ë¦­ (P95, P99 ì‘ë‹µ ì‹œê°„)

### ì„±ëŠ¥ ë©”íŠ¸ë¦­
- **ì‘ë‹µ ì‹œê°„**: API ì‘ë‹µ ì‹œê°„, í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„
- **ì²˜ë¦¬ëŸ‰**: ì´ˆë‹¹ ìš”ì²­ ìˆ˜, ì²˜ë¦¬ëœ ì‘ì—… ìˆ˜
- **ì—ëŸ¬ìœ¨**: ì‹¤íŒ¨í•œ ìš”ì²­ì˜ ë¹„ìœ¨
- **ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰**: CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬, ë„¤íŠ¸ì›Œí¬

### ì €ì¥ì†Œ ìœ í˜•
- **ë©”ëª¨ë¦¬ ì €ì¥ì†Œ**: ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© íœ˜ë°œì„± ì €ì¥ì†Œ
- **Prometheus**: í”„ë¡œë•ì…˜ìš© ì‹œê³„ì—´ ë°ì´í„°ë² ì´ìŠ¤
- **íŒŒì¼ ì €ì¥ì†Œ**: ë¡œì»¬ íŒŒì¼ ê¸°ë°˜ ì €ì¥

## ğŸ“š API ë ˆí¼ëŸ°ìŠ¤

### ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°

```python
from rfs.monitoring.metrics import MetricsCollector, MemoryMetricsStorage

# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ìƒì„±
collector = MetricsCollector(storage=MemoryMetricsStorage())
```

### ë©”íŠ¸ë¦­ íƒ€ì…ë³„ API

#### Counter (ì¹´ìš´í„°)

```python
# ì¹´ìš´í„° ìƒì„±
counter = collector.counter(
    name="http_requests_total",
    description="ì´ HTTP ìš”ì²­ ìˆ˜",
    labels={"method": "GET", "endpoint": "/api/users"}
)

# ê°’ ì¦ê°€
counter.increment()        # 1ì”© ì¦ê°€
counter.increment(5)       # 5ë§Œí¼ ì¦ê°€

# í˜„ì¬ ê°’ ì¡°íšŒ
current_value = counter.get_value()
```

#### Gauge (ê²Œì´ì§€)

```python
# ê²Œì´ì§€ ìƒì„±
gauge = collector.gauge(
    name="active_connections",
    description="í™œì„± ì—°ê²° ìˆ˜",
    labels={"service": "database"}
)

# ê°’ ì„¤ì •
gauge.set(10)              # ê°’ì„ 10ìœ¼ë¡œ ì„¤ì •
gauge.increment(2)         # 2ë§Œí¼ ì¦ê°€
gauge.decrement(1)         # 1ë§Œí¼ ê°ì†Œ
```

#### Histogram (íˆìŠ¤í† ê·¸ë¨)

```python
# íˆìŠ¤í† ê·¸ë¨ ìƒì„±
histogram = collector.histogram(
    name="response_time_seconds",
    buckets=[0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0],
    description="ì‘ë‹µ ì‹œê°„ ë¶„í¬"
)

# ê°’ ê´€ì°°
histogram.observe(0.25)    # 250ms ì‘ë‹µ ì‹œê°„ ê¸°ë¡

# ë¶„ìœ„ìˆ˜ ê³„ì‚°
p95 = histogram.get_quantile(0.95)  # 95ë²ˆì§¸ ë°±ë¶„ìœ„ìˆ˜
```

#### Summary (ì„œë¨¸ë¦¬)

```python
# ì„œë¨¸ë¦¬ ìƒì„±
summary = collector.summary(
    name="request_duration_seconds",
    max_age=600,           # 10ë¶„ê°„ ë°ì´í„° ë³´ê´€
    max_samples=10000,     # ìµœëŒ€ 10,000ê°œ ìƒ˜í”Œ
    description="ìš”ì²­ ì²˜ë¦¬ ì‹œê°„"
)

# ê°’ ê´€ì°°
summary.observe(0.123)

# í†µê³„ ì¡°íšŒ
stats = summary.get_statistics()
# {'count': 1000, 'sum': 123.45, 'mean': 0.123, 'p95': 0.5, 'p99': 0.8}
```

## ğŸ’¡ ì‚¬ìš© ì˜ˆì œ

### ê¸°ë³¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```python
from rfs.monitoring.metrics import (
    get_metrics_collector,
    record_counter,
    record_gauge,
    record_histogram
)

# ê°„ë‹¨í•œ ë©”íŠ¸ë¦­ ê¸°ë¡
record_counter("user_logins", labels={"method": "oauth"})
record_gauge("memory_usage_bytes", 1024 * 1024 * 512)
record_histogram("api_response_time", 0.25)

# ë©”íŠ¸ë¦­ ì¡°íšŒ
collector = get_metrics_collector()
all_metrics = await collector.get_all_metrics()

for metric in all_metrics:
    print(f"{metric.name}: {metric.value}")
```

### ì„±ëŠ¥ ë°ì½”ë ˆì´í„° í™œìš©

```python
from rfs.monitoring.performance_decorators import (
    PerformanceMonitored,
    TimingMetric,
    CounterMetric
)

@PerformanceMonitored(
    timing_metric=TimingMetric("user_service_create_time"),
    counter_metric=CounterMetric("user_service_create_total"),
    error_counter=CounterMetric("user_service_create_errors"),
    labels={"service": "user", "version": "v1"}
)
async def create_user(user_data: dict) -> Result[dict, str]:
    """ì‚¬ìš©ì ìƒì„± (ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í¬í•¨)"""
    try:
        # ì‚¬ìš©ì ìƒì„± ë¡œì§
        user = await save_user_to_db(user_data)
        return Success(user)
    except Exception as e:
        return Failure(str(e))

# ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘:
# - user_service_create_time: ì‹¤í–‰ ì‹œê°„ íˆìŠ¤í† ê·¸ë¨
# - user_service_create_total: ì´ í˜¸ì¶œ ìˆ˜ ì¹´ìš´í„°
# - user_service_create_errors: ì—ëŸ¬ ë°œìƒ ìˆ˜ ì¹´ìš´í„°
```

### ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ëª¨ë‹ˆí„°ë§

```python
from rfs.monitoring.metrics import get_metrics_collector
from rfs.core.result import Result, Success
import time

class WebService:
    def __init__(self):
        self.collector = get_metrics_collector()
        
        # ë©”íŠ¸ë¦­ ì •ì˜
        self.request_counter = self.collector.counter(
            "http_requests_total",
            description="ì´ HTTP ìš”ì²­ ìˆ˜",
            labels={"service": "web"}
        )
        
        self.response_time = self.collector.histogram(
            "http_request_duration_seconds",
            buckets=[0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0],
            description="HTTP ì‘ë‹µ ì‹œê°„"
        )
        
        self.active_requests = self.collector.gauge(
            "http_requests_active",
            description="í™œì„± HTTP ìš”ì²­ ìˆ˜"
        )
    
    async def handle_request(self, request) -> Result[dict, str]:
        """HTTP ìš”ì²­ ì²˜ë¦¬ (ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í¬í•¨)"""
        start_time = time.time()
        
        # í™œì„± ìš”ì²­ ìˆ˜ ì¦ê°€
        self.active_requests.increment()
        
        try:
            # ìš”ì²­ ì¹´ìš´í„° ì¦ê°€
            self.request_counter.increment()
            
            # ì‹¤ì œ ìš”ì²­ ì²˜ë¦¬
            response = await self._process_request(request)
            
            # ì„±ê³µ ë©”íŠ¸ë¦­ ê¸°ë¡
            duration = time.time() - start_time
            self.response_time.observe(duration)
            
            return Success(response)
            
        except Exception as e:
            # ì—ëŸ¬ ë©”íŠ¸ë¦­ ê¸°ë¡
            error_counter = self.collector.counter(
                "http_errors_total",
                labels={"error_type": type(e).__name__}
            )
            error_counter.increment()
            
            return Failure(str(e))
            
        finally:
            # í™œì„± ìš”ì²­ ìˆ˜ ê°ì†Œ
            self.active_requests.decrement()
```

### ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ëª¨ë‹ˆí„°ë§

```python
from rfs.monitoring.metrics import get_metrics_collector
import asyncio
import time

class DatabasePool:
    def __init__(self, max_connections: int = 10):
        self.max_connections = max_connections
        self.collector = get_metrics_collector()
        
        # ì—°ê²° ë©”íŠ¸ë¦­
        self.connection_pool_size = self.collector.gauge(
            "db_connection_pool_size",
            description="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ í¬ê¸°"
        )
        
        self.active_connections = self.collector.gauge(
            "db_connections_active",
            description="í™œì„± ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìˆ˜"
        )
        
        self.query_duration = self.collector.histogram(
            "db_query_duration_seconds",
            buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],
            description="ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„"
        )
        
        self.connection_errors = self.collector.counter(
            "db_connection_errors_total",
            description="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì—ëŸ¬ ìˆ˜"
        )
        
        # ì´ˆê¸° ë©”íŠ¸ë¦­ ì„¤ì •
        self.connection_pool_size.set(max_connections)
    
    async def execute_query(self, query: str) -> Result[list, str]:
        """ì¿¼ë¦¬ ì‹¤í–‰ (ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í¬í•¨)"""
        start_time = time.time()
        
        # í™œì„± ì—°ê²° ìˆ˜ ì¦ê°€
        self.active_connections.increment()
        
        try:
            # ì¿¼ë¦¬ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜
            await asyncio.sleep(0.05)  # 50ms ì‹œë®¬ë ˆì´ì…˜
            result = [{"id": 1, "name": "test"}]
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
            duration = time.time() - start_time
            self.query_duration.observe(duration)
            
            return Success(result)
            
        except Exception as e:
            self.connection_errors.increment()
            return Failure(str(e))
            
        finally:
            # í™œì„± ì—°ê²° ìˆ˜ ê°ì†Œ
            self.active_connections.decrement()
```

### ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§

```python
from rfs.monitoring.metrics import get_metrics_collector

class OrderService:
    def __init__(self):
        self.collector = get_metrics_collector()
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
        self.orders_total = self.collector.counter(
            "orders_created_total",
            description="ìƒì„±ëœ ì£¼ë¬¸ ìˆ˜"
        )
        
        self.order_value = self.collector.histogram(
            "order_value_distribution",
            buckets=[10, 50, 100, 500, 1000, 5000, 10000],
            description="ì£¼ë¬¸ ê¸ˆì•¡ ë¶„í¬"
        )
        
        self.payment_success_rate = self.collector.gauge(
            "payment_success_rate",
            description="ê²°ì œ ì„±ê³µë¥ "
        )
        
        self.inventory_levels = self.collector.gauge(
            "inventory_remaining",
            description="ì¬ê³  ìˆ˜ì¤€"
        )
    
    async def create_order(self, order_data: dict) -> Result[dict, str]:
        """ì£¼ë¬¸ ìƒì„± (ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘)"""
        try:
            # ì£¼ë¬¸ ìƒì„±
            order = await self._create_order_in_db(order_data)
            
            # ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self.orders_total.increment()
            self.order_value.observe(order["amount"])
            
            # ì¬ê³  ìˆ˜ì¤€ ì—…ë°ì´íŠ¸
            remaining_inventory = await self._get_inventory_count(order["product_id"])
            self.inventory_levels.set(
                remaining_inventory,
                labels={"product_id": order["product_id"]}
            )
            
            return Success(order)
            
        except Exception as e:
            return Failure(str(e))
```

### Prometheus í†µí•©

```python
from rfs.monitoring.metrics import PrometheusStorage, MetricsCollector

# Prometheus Push Gateway ì„¤ì •
prometheus_storage = PrometheusStorage(
    push_gateway_url="http://pushgateway:9091",
    job_name="rfs_application"
)

# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ìƒì„±
collector = MetricsCollector(storage=prometheus_storage)

# ë©”íŠ¸ë¦­ ì •ì˜ ë° ì‚¬ìš©
request_counter = collector.counter(
    "app_requests_total",
    labels={"service": "api", "version": "v1"}
)

# ì£¼ê¸°ì ìœ¼ë¡œ ë©”íŠ¸ë¦­ì„ Prometheusë¡œ ì „ì†¡
import asyncio

async def push_metrics_periodically():
    """ë©”íŠ¸ë¦­ì„ ì£¼ê¸°ì ìœ¼ë¡œ Prometheusë¡œ ì „ì†¡"""
    while True:
        try:
            result = await collector.collect_and_store()
            if result.is_success():
                print(f"ë©”íŠ¸ë¦­ {result.unwrap()}ê°œ ì „ì†¡ ì™„ë£Œ")
            else:
                print(f"ë©”íŠ¸ë¦­ ì „ì†¡ ì‹¤íŒ¨: {result.unwrap_err()}")
        except Exception as e:
            print(f"ë©”íŠ¸ë¦­ ì „ì†¡ ì¤‘ ì—ëŸ¬: {e}")
        
        await asyncio.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì „ì†¡
```

### ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ë°ì´í„°

```python
from rfs.monitoring.metrics import get_metrics_collector
import json

class MetricsDashboard:
    def __init__(self):
        self.collector = get_metrics_collector()
    
    async def get_dashboard_data(self) -> dict:
        """ëŒ€ì‹œë³´ë“œìš© ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒ"""
        all_metrics = await self.collector.get_all_metrics()
        
        dashboard_data = {
            "system": {
                "uptime": self._get_uptime_metric(all_metrics),
                "memory_usage": self._get_memory_metric(all_metrics),
                "cpu_usage": self._get_cpu_metric(all_metrics)
            },
            "application": {
                "requests_per_second": self._calculate_rps(all_metrics),
                "error_rate": self._calculate_error_rate(all_metrics),
                "response_time_p95": self._get_response_time_p95(all_metrics)
            },
            "business": {
                "orders_today": self._get_orders_today(all_metrics),
                "revenue_today": self._get_revenue_today(all_metrics),
                "active_users": self._get_active_users(all_metrics)
            }
        }
        
        return dashboard_data
    
    def _get_uptime_metric(self, metrics):
        """ì‹œìŠ¤í…œ ê°€ë™ ì‹œê°„"""
        for metric in metrics:
            if metric.name == "system_uptime_seconds":
                return metric.value
        return 0
    
    def _calculate_rps(self, metrics):
        """ì´ˆë‹¹ ìš”ì²­ ìˆ˜ ê³„ì‚°"""
        # êµ¬í˜„ ë¡œì§...
        return 0
    
    async def export_metrics_json(self) -> str:
        """ë©”íŠ¸ë¦­ì„ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        all_metrics = await self.collector.get_all_metrics()
        
        metrics_data = []
        for metric in all_metrics:
            metrics_data.append({
                "name": metric.name,
                "type": metric.metric_type.value,
                "value": metric.value,
                "labels": metric.labels,
                "timestamp": metric.timestamp,
                "description": metric.description
            })
        
        return json.dumps(metrics_data, indent=2)
```

## ğŸ¨ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### 1. ë©”íŠ¸ë¦­ ëª…ëª… ê·œì¹™

```python
# âœ… ì¢‹ì€ ì˜ˆ - ëª…í™•í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì™€ ì˜ë¯¸
collector.counter("http_requests_total", labels={"method": "GET"})
collector.histogram("database_query_duration_seconds")
collector.gauge("memory_usage_bytes")

# âŒ ë‚˜ìœ ì˜ˆ - ëª¨í˜¸í•œ ì´ë¦„
collector.counter("requests")
collector.histogram("time")
collector.gauge("mem")
```

### 2. ë¼ë²¨ ì‚¬ìš©

```python
# âœ… ì¢‹ì€ ì˜ˆ - ì ì ˆí•œ ë¼ë²¨ ì‚¬ìš©
collector.counter(
    "api_requests_total",
    labels={
        "method": "POST",
        "endpoint": "/api/users",
        "status_code": "200",
        "service": "user_service"
    }
)

# âŒ ë‚˜ìœ ì˜ˆ - ê³¼ë„í•œ ë¼ë²¨ (ì¹´ë””ë„ë¦¬í‹° í­ë°œ)
collector.counter(
    "requests",
    labels={
        "user_id": "user123",  # ë†’ì€ ì¹´ë””ë„ë¦¬í‹°
        "timestamp": "2024-01-15T10:30:00Z",  # ë§¤ìš° ë†’ì€ ì¹´ë””ë„ë¦¬í‹°
        "request_id": "req-456"  # ë§¤ìš° ë†’ì€ ì¹´ë””ë„ë¦¬í‹°
    }
)
```

### 3. íˆìŠ¤í† ê·¸ë¨ ë²„í‚· ì„¤ì •

```python
# âœ… ì¢‹ì€ ì˜ˆ - ì ì ˆí•œ ë²„í‚· ë²”ìœ„
response_time_histogram = collector.histogram(
    "api_response_time_seconds",
    buckets=[0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0],
    description="API ì‘ë‹µ ì‹œê°„ ë¶„í¬"
)

# ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ìš© (ë” ì‘ì€ ë²”ìœ„)
db_query_histogram = collector.histogram(
    "db_query_duration_seconds",
    buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],
    description="ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‹œê°„"
)
```

### 4. ì„±ëŠ¥ ìµœì í™”

```python
# âœ… ì¢‹ì€ ì˜ˆ - ë©”íŠ¸ë¦­ ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš©
class ServiceMetrics:
    def __init__(self):
        self.collector = get_metrics_collector()
        self.request_counter = self.collector.counter("requests_total")
        self.response_histogram = self.collector.histogram("response_time")
    
    def record_request(self):
        self.request_counter.increment()  # ë¹ ë¦„ - ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš©

# âŒ ë‚˜ìœ ì˜ˆ - ë§¤ë²ˆ ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ ìƒì„±
def record_request():
    collector = get_metrics_collector()
    counter = collector.counter("requests_total")  # ëŠë¦¼ - ë§¤ë²ˆ ìƒì„±
    counter.increment()
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. ë©”íŠ¸ë¦­ ì¹´ë””ë„ë¦¬í‹° ê´€ë¦¬
- ë¼ë²¨ ê°’ì˜ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€
- ì‚¬ìš©ì ID, íƒ€ì„ìŠ¤íƒ¬í”„ ë“± ë†’ì€ ì¹´ë””ë„ë¦¬í‹° ë°ì´í„° ë¼ë²¨ ì‚¬ìš© ê¸ˆì§€

### 2. ì„±ëŠ¥ ì˜í–¥ ìµœì†Œí™”
- ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ëª¨ë‹ˆí„°ë§
- ë¶ˆí•„ìš”í•œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì§€ì–‘

### 3. ë©”íŠ¸ë¦­ ì €ì¥ì†Œ ìš©ëŸ‰
- íˆìŠ¤í† ê·¸ë¨ê³¼ ì„œë¨¸ë¦¬ëŠ” ë§ì€ ì €ì¥ ê³µê°„ ì‚¬ìš©
- ì ì ˆí•œ ë³´ê´€ ê¸°ê°„ ì„¤ì • ë° ì •ë¦¬ ì •ì±… ìˆ˜ë¦½

### 4. ì•Œë¦¼ ì„ê³„ê°’ ì„¤ì •
- ì ì ˆí•œ ì„ê³„ê°’ ì„¤ì •ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ ì•Œë¦¼ ë°©ì§€
- ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” SLA ê¸°ë°˜ ì•Œë¦¼

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ
- [ë¡œê¹…](./07-logging.md) - êµ¬ì¡°í™”ëœ ë¡œê¹…ê³¼ ë©”íŠ¸ë¦­ ì—°ë™
- [ë°°í¬](./05-deployment.md) - í”„ë¡œë•ì…˜ í™˜ê²½ ëª¨ë‹ˆí„°ë§ ì„¤ì •
- [ë³´ì•ˆ](./11-security.md) - ë³´ì•ˆ ë©”íŠ¸ë¦­ ë° ì´ìƒ íƒì§€
- [ì„œí‚· ë¸Œë ˆì´ì»¤](./12-circuit-breaker.md) - ì¥ì•  ê²©ë¦¬ ë©”íŠ¸ë¦­