# ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ìƒì„¸ ì‚¬ì–‘ì„œ

**ë¬¸ì„œ ë²„ì „**: 1.0  
**ì‘ì„±ì¼**: 2025-09-03  
**ìƒíƒœ**: ì„¤ê³„ ì™„ë£Œ

---

## ğŸ“‹ ê°œìš”

Phase 1ì˜ MonoResult/FluxResultì™€ Phase 2ì˜ FastAPI í†µí•©ì„ ê¸°ë°˜ìœ¼ë¡œ, í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ Result íŒ¨í„´ì„ ì™„ì „í•˜ê²Œ ê´€ì¸¡í•˜ê³  ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì˜ ìƒì„¸ ì‚¬ì–‘ì…ë‹ˆë‹¤.

---

## ğŸ¯ 1. Result ë¡œê¹… í™•ì¥ (`result_logging.py`)

### 1.1 MonoResult ë¡œê¹… ë©”ì„œë“œ í™•ì¥

**ëª©ì **: MonoResultì— ë¡œê¹… ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ì—¬ ê° ë‹¨ê³„ë³„ ì‹¤í–‰ ê³¼ì •ì„ ì¶”ì 

#### êµ¬í˜„ ì‚¬ì–‘
```python
# MonoResult í´ë˜ìŠ¤ì— ì¶”ê°€í•  ë©”ì„œë“œë“¤
class MonoResult(Generic[T, E]):
    
    def log_step(self, step_name: str, log_level: str = "INFO") -> "MonoResult[T, E]":
        """
        íŒŒì´í”„ë¼ì¸ì˜ íŠ¹ì • ë‹¨ê³„ë¥¼ ë¡œê¹…
        
        Args:
            step_name: ë‹¨ê³„ ì´ë¦„ (ì˜ˆ: "user_validation", "data_transform")
            log_level: ë¡œê·¸ ë ˆë²¨ ("DEBUG", "INFO", "WARNING", "ERROR")
            
        Returns:
            MonoResult: ë¡œê¹…ì´ ì¶”ê°€ëœ MonoResult (ì²´ì´ë‹ ê°€ëŠ¥)
            
        Example:
            result = await (
                MonoResult.from_async_result(fetch_user)
                .log_step("user_fetch", "INFO")
                .bind_result(validate_user)
                .log_step("user_validation", "DEBUG")  
                .to_result()
            )
        """
        async def logged_step():
            start_time = time.time()
            correlation_id = get_correlation_id()
            
            logger.log(
                getattr(logging, log_level),
                f"[{correlation_id}] ë‹¨ê³„ ì‹œì‘: {step_name}"
            )
            
            try:
                result = await self._async_func()
                processing_time = (time.time() - start_time) * 1000
                
                if result.is_success():
                    logger.log(
                        getattr(logging, log_level),
                        f"[{correlation_id}] ë‹¨ê³„ ì„±ê³µ: {step_name} "
                        f"({processing_time:.2f}ms)"
                    )
                    
                    # êµ¬ì¡°í™”ëœ ë¡œê·¸ ì—”íŠ¸ë¦¬ ìƒì„±
                    log_entry = ResultLogEntry(
                        timestamp=datetime.now(),
                        correlation_id=correlation_id,
                        operation_name=get_current_operation_name(),
                        step_name=step_name,
                        result_type="success",
                        processing_time_ms=processing_time,
                        success_type=type(result.unwrap()).__name__
                    )
                    structured_logger.log_result_entry(log_entry)
                    
                else:
                    error = result.unwrap_error()
                    logger.log(
                        logging.WARNING,
                        f"[{correlation_id}] ë‹¨ê³„ ì‹¤íŒ¨: {step_name} "
                        f"({processing_time:.2f}ms) - {error}"
                    )
                    
                    # êµ¬ì¡°í™”ëœ ì—ëŸ¬ ë¡œê·¸
                    log_entry = ResultLogEntry(
                        timestamp=datetime.now(),
                        correlation_id=correlation_id,
                        operation_name=get_current_operation_name(),
                        step_name=step_name,
                        result_type="error",
                        processing_time_ms=processing_time,
                        error_type=type(error).__name__,
                        error_code=getattr(error, 'code', None),
                        error_message=str(error)
                    )
                    structured_logger.log_result_entry(log_entry)
                
                return result
                
            except Exception as e:
                processing_time = (time.time() - start_time) * 1000
                logger.error(
                    f"[{correlation_id}] ë‹¨ê³„ ì˜ˆì™¸: {step_name} "
                    f"({processing_time:.2f}ms) - {e}"
                )
                
                # ì˜ˆì™¸ ë¡œê·¸
                log_entry = ResultLogEntry(
                    timestamp=datetime.now(),
                    correlation_id=correlation_id,
                    operation_name=get_current_operation_name(),
                    step_name=step_name,
                    result_type="error",
                    processing_time_ms=processing_time,
                    error_type=type(e).__name__,
                    error_message=str(e)
                )
                structured_logger.log_result_entry(log_entry)
                
                return Failure(e)
        
        return MonoResult(logged_step)
    
    def log_error(self, error_context: str) -> "MonoResult[T, E]":
        """
        ì—ëŸ¬ ë°œìƒ ì‹œì—ë§Œ ë¡œê¹… (ì„±ê³µ ì‹œì—ëŠ” ë¡œê¹…í•˜ì§€ ì•ŠìŒ)
        
        Args:
            error_context: ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì„¤ëª…
            
        Example:
            result = await (
                MonoResult.from_async_result(risky_operation)
                .log_error("critical_operation_failure")
                .to_result()
            )
        """
        async def error_logged():
            result = await self._async_func()
            
            if result.is_failure():
                correlation_id = get_correlation_id()
                error = result.unwrap_error()
                
                logger.error(
                    f"[{correlation_id}] ì—ëŸ¬ ë°œìƒ - {error_context}: {error}"
                )
                
                # ì—ëŸ¬ ì „ìš© êµ¬ì¡°í™”ëœ ë¡œê¹…
                log_entry = ResultLogEntry(
                    timestamp=datetime.now(),
                    correlation_id=correlation_id,
                    operation_name=get_current_operation_name(),
                    step_name=error_context,
                    result_type="error",
                    processing_time_ms=0.0,  # ì´ë¯¸ ì²˜ë¦¬ ì™„ë£Œëœ ìƒíƒœ
                    error_type=type(error).__name__,
                    error_code=getattr(error, 'code', None),
                    error_message=str(error)
                )
                structured_logger.log_result_entry(log_entry)
            
            return result
        
        return MonoResult(error_logged)
    
    def log_performance(self, performance_threshold_ms: float = 1000.0) -> "MonoResult[T, E]":
        """
        ì„±ëŠ¥ ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ëŠ” ê²½ìš°ì—ë§Œ ë¡œê¹…
        
        Args:
            performance_threshold_ms: ì„±ëŠ¥ ì„ê³„ê°’ (ë°€ë¦¬ì´ˆ)
            
        Example:
            result = await (
                MonoResult.from_async_result(slow_operation)
                .log_performance(500.0)  # 500ms ì´ˆê³¼ ì‹œ ë¡œê¹…
                .to_result()
            )
        """
        async def performance_logged():
            start_time = time.time()
            result = await self._async_func()
            processing_time = (time.time() - start_time) * 1000
            
            if processing_time > performance_threshold_ms:
                correlation_id = get_correlation_id()
                logger.warning(
                    f"[{correlation_id}] ì„±ëŠ¥ ì„ê³„ê°’ ì´ˆê³¼: "
                    f"{processing_time:.2f}ms (ì„ê³„ê°’: {performance_threshold_ms}ms)"
                )
                
                # ì„±ëŠ¥ ë¡œê·¸
                log_entry = ResultLogEntry(
                    timestamp=datetime.now(),
                    correlation_id=correlation_id,
                    operation_name=get_current_operation_name(),
                    step_name="performance_check",
                    result_type="success" if result.is_success() else "error",
                    processing_time_ms=processing_time,
                    metadata={
                        "performance_threshold_ms": performance_threshold_ms,
                        "threshold_exceeded": True
                    }
                )
                structured_logger.log_result_entry(log_entry)
            
            return result
        
        return MonoResult(performance_logged)
```

### 1.2 @log_result_operation ë°ì½”ë ˆì´í„°

**ëª©ì **: ì „ì²´ ì‘ì—…(operation)ì„ ìë™ìœ¼ë¡œ ë¡œê¹…í•˜ëŠ” ë°ì½”ë ˆì´í„°

#### êµ¬í˜„ ì‚¬ì–‘
```python
from functools import wraps
from typing import Callable, Optional
import uuid

def log_result_operation(
    operation_name: str,
    log_level: str = "INFO",
    include_args: bool = False,
    mask_sensitive: bool = True,
    performance_threshold_ms: Optional[float] = None
) -> Callable:
    """
    Resultë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì˜ ì „ì²´ ì‹¤í–‰ì„ ìë™ ë¡œê¹…
    
    Args:
        operation_name: ì‘ì—… ì´ë¦„ (ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì—ë„ ì‚¬ìš©ë¨)
        log_level: ë¡œê·¸ ë ˆë²¨
        include_args: í•¨ìˆ˜ ì¸ìë¥¼ ë¡œê·¸ì— í¬í•¨í• ì§€ ì—¬ë¶€
        mask_sensitive: ë¯¼ê° ì •ë³´ ë§ˆìŠ¤í‚¹ ì—¬ë¶€
        performance_threshold_ms: ì„±ëŠ¥ ì„ê³„ê°’ (ì´ˆê³¼ ì‹œ WARNING ë¡œê·¸)
        
    Example:
        @log_result_operation("user_retrieval", include_args=True)
        async def get_user(user_id: str) -> Result[User, APIError]:
            return await user_service.get_user(user_id)
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # Correlation ID ìƒì„± ë° ì„¤ì •
            correlation_id = str(uuid.uuid4())
            set_correlation_id(correlation_id)
            set_current_operation_name(operation_name)
            
            start_time = time.time()
            
            # í•¨ìˆ˜ ì¸ì ë¡œê¹… (ì˜µì…˜)
            args_info = ""
            if include_args:
                masked_args = mask_sensitive_data(args, kwargs) if mask_sensitive else (args, kwargs)
                args_info = f" - ì¸ì: {masked_args}"
            
            logger.log(
                getattr(logging, log_level),
                f"[{correlation_id}] ì‘ì—… ì‹œì‘: {operation_name}{args_info}"
            )
            
            try:
                result = await func(*args, **kwargs)
                processing_time = (time.time() - start_time) * 1000
                
                # ì„±ëŠ¥ ì„ê³„ê°’ ì²´í¬
                log_level_final = log_level
                if performance_threshold_ms and processing_time > performance_threshold_ms:
                    log_level_final = "WARNING"
                
                if result.is_success():
                    logger.log(
                        getattr(logging, log_level_final),
                        f"[{correlation_id}] ì‘ì—… ì™„ë£Œ: {operation_name} "
                        f"({processing_time:.2f}ms) - ì„±ê³µ"
                    )
                else:
                    error = result.unwrap_error()
                    logger.log(
                        logging.WARNING,
                        f"[{correlation_id}] ì‘ì—… ì™„ë£Œ: {operation_name} "
                        f"({processing_time:.2f}ms) - ì‹¤íŒ¨: {error}"
                    )
                
                # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                metrics_collector = ResultMetricsCollector.instance()
                metrics_collector.record_operation(
                    operation_name=operation_name,
                    success=result.is_success(),
                    processing_time_ms=processing_time,
                    error_type=type(result.unwrap_error()).__name__ if result.is_failure() else None
                )
                
                # êµ¬ì¡°í™”ëœ ì‘ì—… ë¡œê·¸
                log_entry = ResultLogEntry(
                    timestamp=datetime.now(),
                    correlation_id=correlation_id,
                    operation_name=operation_name,
                    step_name="operation_complete",
                    result_type="success" if result.is_success() else "error",
                    processing_time_ms=processing_time,
                    success_type=type(result.unwrap()).__name__ if result.is_success() else None,
                    error_type=type(result.unwrap_error()).__name__ if result.is_failure() else None,
                    error_code=getattr(result.unwrap_error(), 'code', None) if result.is_failure() else None,
                    error_message=str(result.unwrap_error()) if result.is_failure() else None,
                    metadata={
                        "function_name": func.__name__,
                        "module_name": func.__module__
                    }
                )
                structured_logger.log_result_entry(log_entry)
                
                return result
                
            except Exception as e:
                processing_time = (time.time() - start_time) * 1000
                logger.error(
                    f"[{correlation_id}] ì‘ì—… ì˜ˆì™¸: {operation_name} "
                    f"({processing_time:.2f}ms) - {type(e).__name__}: {e}"
                )
                
                # ì˜ˆì™¸ ë©”íŠ¸ë¦­ ê¸°ë¡
                metrics_collector = ResultMetricsCollector.instance()
                metrics_collector.record_operation(
                    operation_name=operation_name,
                    success=False,
                    processing_time_ms=processing_time,
                    error_type=type(e).__name__
                )
                
                # ì˜ˆì™¸ë¥¼ Resultë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
                api_error = APIError.from_exception(e)
                return Failure(api_error)
                
            finally:
                # Correlation ID ì •ë¦¬
                clear_correlation_id()
                clear_current_operation_name()
        
        return wrapper
    
    return decorator
```

---

## ğŸ“Š 2. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œ (`metrics.py`)

### 2.1 ResultMetricsCollector í´ë˜ìŠ¤

**ëª©ì **: Result íŒ¨í„´ ê¸°ë°˜ ì‘ì—…ì˜ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜ì§‘

#### êµ¬í˜„ ì‚¬ì–‘
```python
from collections import defaultdict, deque
from threading import Lock
import threading
from typing import Dict, List, Optional
from datetime import datetime, timedelta
import statistics

class ResultMetricsCollector:
    """Result íŒ¨í„´ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° (Singleton)"""
    
    _instance = None
    _instance_lock = Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._instance_lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not hasattr(self, 'initialized'):
            self.initialized = True
            self._metrics_lock = Lock()
            self._operation_metrics: Dict[str, deque] = defaultdict(
                lambda: deque(maxlen=10000)  # ìµœëŒ€ 10,000ê°œ ê¸°ë¡ ìœ ì§€
            )
            self._error_counts: Dict[str, Dict[str, int]] = defaultdict(
                lambda: defaultdict(int)
            )
            self._hourly_stats: Dict[str, Dict[int, int]] = defaultdict(
                lambda: defaultdict(int)
            )
    
    def record_operation(
        self,
        operation_name: str,
        success: bool,
        processing_time_ms: float,
        error_type: Optional[str] = None,
        user_id: Optional[str] = None,
        metadata: Optional[Dict] = None
    ):
        """
        ì‘ì—… ì‹¤í–‰ ê²°ê³¼ë¥¼ ë©”íŠ¸ë¦­ìœ¼ë¡œ ê¸°ë¡
        
        Args:
            operation_name: ì‘ì—… ì´ë¦„
            success: ì„±ê³µ ì—¬ë¶€
            processing_time_ms: ì²˜ë¦¬ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
            error_type: ì—ëŸ¬ íƒ€ì… (ì‹¤íŒ¨ ì‹œ)
            user_id: ì‚¬ìš©ì ID (ì˜µì…˜)
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
        """
        with self._metrics_lock:
            timestamp = datetime.now()
            
            # ê¸°ë³¸ ë©”íŠ¸ë¦­ ê¸°ë¡
            metric_entry = {
                'timestamp': timestamp,
                'success': success,
                'processing_time_ms': processing_time_ms,
                'error_type': error_type,
                'user_id': user_id,
                'metadata': metadata or {}
            }
            
            self._operation_metrics[operation_name].append(metric_entry)
            
            # ì—ëŸ¬ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
            if not success and error_type:
                self._error_counts[operation_name][error_type] += 1
            
            # ì‹œê°„ëŒ€ë³„ í†µê³„ ì—…ë°ì´íŠ¸
            hour = timestamp.hour
            self._hourly_stats[operation_name][hour] += 1
    
    def get_operation_metrics(
        self,
        operation_name: str,
        time_range: str = "1h"
    ) -> OperationMetrics:
        """
        íŠ¹ì • ì‘ì—…ì˜ ë©”íŠ¸ë¦­ì„ ì¡°íšŒ
        
        Args:
            operation_name: ì‘ì—… ì´ë¦„
            time_range: ì‹œê°„ ë²”ìœ„ ("1h", "1d", "1w")
            
        Returns:
            OperationMetrics: ì§‘ê³„ëœ ë©”íŠ¸ë¦­ ë°ì´í„°
        """
        with self._metrics_lock:
            # ì‹œê°„ ë²”ìœ„ í•„í„°ë§
            cutoff_time = self._get_cutoff_time(time_range)
            filtered_metrics = [
                m for m in self._operation_metrics[operation_name]
                if m['timestamp'] >= cutoff_time
            ]
            
            if not filtered_metrics:
                return OperationMetrics(
                    operation_name=operation_name,
                    time_window=time_range,
                    total_requests=0,
                    successful_requests=0,
                    failed_requests=0,
                    success_rate=0.0,
                    avg_response_time_ms=0.0,
                    p50_response_time_ms=0.0,
                    p90_response_time_ms=0.0,
                    p99_response_time_ms=0.0,
                    max_response_time_ms=0.0,
                    error_breakdown={},
                    top_errors=[],
                    avg_memory_usage_mb=0.0,
                    avg_cpu_usage_percent=0.0,
                    hourly_distribution={}
                )
            
            # ê¸°ë³¸ í†µê³„
            total_requests = len(filtered_metrics)
            successful_requests = sum(1 for m in filtered_metrics if m['success'])
            failed_requests = total_requests - successful_requests
            success_rate = successful_requests / total_requests if total_requests > 0 else 0.0
            
            # ì‘ë‹µ ì‹œê°„ í†µê³„
            response_times = [m['processing_time_ms'] for m in filtered_metrics]
            avg_response_time = statistics.mean(response_times)
            
            # ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°
            sorted_times = sorted(response_times)
            p50_response_time = self._percentile(sorted_times, 0.5)
            p90_response_time = self._percentile(sorted_times, 0.9)
            p99_response_time = self._percentile(sorted_times, 0.99)
            max_response_time = max(response_times)
            
            # ì—ëŸ¬ í†µê³„
            error_breakdown = defaultdict(int)
            for m in filtered_metrics:
                if not m['success'] and m['error_type']:
                    error_breakdown[m['error_type']] += 1
            
            top_errors = sorted(
                error_breakdown.items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]
            
            # ì‹œê°„ëŒ€ë³„ ë¶„í¬
            hourly_distribution = defaultdict(int)
            for m in filtered_metrics:
                hour = m['timestamp'].hour
                hourly_distribution[hour] += 1
            
            return OperationMetrics(
                operation_name=operation_name,
                time_window=time_range,
                total_requests=total_requests,
                successful_requests=successful_requests,
                failed_requests=failed_requests,
                success_rate=success_rate,
                avg_response_time_ms=avg_response_time,
                p50_response_time_ms=p50_response_time,
                p90_response_time_ms=p90_response_time,
                p99_response_time_ms=p99_response_time,
                max_response_time_ms=max_response_time,
                error_breakdown=dict(error_breakdown),
                top_errors=top_errors,
                avg_memory_usage_mb=0.0,  # TODO: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìˆ˜ì§‘
                avg_cpu_usage_percent=0.0,  # TODO: CPU ì‚¬ìš©ëŸ‰ ìˆ˜ì§‘
                hourly_distribution=dict(hourly_distribution)
            )
    
    def _get_cutoff_time(self, time_range: str) -> datetime:
        """ì‹œê°„ ë²”ìœ„ì— ë”°ë¥¸ cut-off ì‹œê°„ ê³„ì‚°"""
        now = datetime.now()
        if time_range == "1h":
            return now - timedelta(hours=1)
        elif time_range == "1d":
            return now - timedelta(days=1)
        elif time_range == "1w":
            return now - timedelta(weeks=1)
        else:
            return now - timedelta(hours=1)
    
    def _percentile(self, sorted_data: List[float], percentile: float) -> float:
        """ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°"""
        if not sorted_data:
            return 0.0
        
        index = percentile * (len(sorted_data) - 1)
        if index.is_integer():
            return sorted_data[int(index)]
        else:
            lower = sorted_data[int(index)]
            upper = sorted_data[int(index) + 1]
            return lower + (upper - lower) * (index - int(index))
    
    @classmethod
    def instance(cls) -> "ResultMetricsCollector":
        """ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ì ‘ê·¼"""
        return cls()
```

---

## ğŸš¨ 3. ì•Œë¦¼ ì‹œìŠ¤í…œ (`alerts.py`)

### 3.1 ì„ê³„ê°’ ê¸°ë°˜ ì•Œë¦¼

#### êµ¬í˜„ ì‚¬ì–‘
```python
from enum import Enum
from dataclasses import dataclass
from typing import Callable, Dict, Any, List
import asyncio
from abc import ABC, abstractmethod

class AlertSeverity(str, Enum):
    """ì•Œë¦¼ ì‹¬ê°ë„"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class AlertCondition(str, Enum):
    """ì•Œë¦¼ ì¡°ê±´"""
    ERROR_RATE_THRESHOLD = "error_rate_threshold"
    RESPONSE_TIME_THRESHOLD = "response_time_threshold"
    FAILURE_COUNT_THRESHOLD = "failure_count_threshold"
    CONSECUTIVE_FAILURES = "consecutive_failures"

@dataclass
class AlertRule:
    """ì•Œë¦¼ ê·œì¹™"""
    name: str
    operation_name: str
    condition: AlertCondition
    threshold_value: float
    time_window: str  # "5m", "1h", "1d"
    severity: AlertSeverity
    enabled: bool = True
    
    # ì•Œë¦¼ ì„¤ì •
    cooldown_minutes: int = 15  # ë™ì¼ ì•Œë¦¼ ì¬ë°œì†¡ ë°©ì§€ ì‹œê°„
    
    def __post_init__(self):
        self.last_triggered = None

@dataclass
class AlertEvent:
    """ì•Œë¦¼ ì´ë²¤íŠ¸"""
    rule_name: str
    operation_name: str
    severity: AlertSeverity
    message: str
    current_value: float
    threshold_value: float
    timestamp: datetime
    metadata: Dict[str, Any]

class AlertNotifier(ABC):
    """ì•Œë¦¼ ì „ì†¡ ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    async def send_alert(self, alert_event: AlertEvent) -> bool:
        """ì•Œë¦¼ ì „ì†¡"""
        pass

class LogAlertNotifier(AlertNotifier):
    """ë¡œê·¸ ê¸°ë°˜ ì•Œë¦¼ ì „ì†¡ê¸°"""
    
    async def send_alert(self, alert_event: AlertEvent) -> bool:
        logger = logging.getLogger("rfs.alerts")
        logger.log(
            self._severity_to_log_level(alert_event.severity),
            f"ğŸš¨ ì•Œë¦¼: {alert_event.rule_name} - {alert_event.message}"
        )
        return True
    
    def _severity_to_log_level(self, severity: AlertSeverity) -> int:
        mapping = {
            AlertSeverity.LOW: logging.INFO,
            AlertSeverity.MEDIUM: logging.WARNING,
            AlertSeverity.HIGH: logging.ERROR,
            AlertSeverity.CRITICAL: logging.CRITICAL
        }
        return mapping.get(severity, logging.WARNING)

class ResultAlertManager:
    """Result íŒ¨í„´ ê¸°ë°˜ ì•Œë¦¼ ê´€ë¦¬ì"""
    
    def __init__(self):
        self._alert_rules: Dict[str, AlertRule] = {}
        self._notifiers: List[AlertNotifier] = []
        self._metrics_collector = ResultMetricsCollector.instance()
        self._check_interval = 60  # 1ë¶„ë§ˆë‹¤ ì²´í¬
        self._running = False
        self._check_task = None
    
    def add_alert_rule(self, rule: AlertRule):
        """ì•Œë¦¼ ê·œì¹™ ì¶”ê°€"""
        self._alert_rules[rule.name] = rule
    
    def remove_alert_rule(self, rule_name: str):
        """ì•Œë¦¼ ê·œì¹™ ì œê±°"""
        self._alert_rules.pop(rule_name, None)
    
    def add_notifier(self, notifier: AlertNotifier):
        """ì•Œë¦¼ ì „ì†¡ê¸° ì¶”ê°€"""
        self._notifiers.append(notifier)
    
    async def start_monitoring(self):
        """ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self._running:
            return
        
        self._running = True
        self._check_task = asyncio.create_task(self._monitoring_loop())
    
    async def stop_monitoring(self):
        """ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self._running = False
        if self._check_task:
            self._check_task.cancel()
            try:
                await self._check_task
            except asyncio.CancelledError:
                pass
    
    async def _monitoring_loop(self):
        """ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self._running:
            try:
                await self._check_all_rules()
                await asyncio.sleep(self._check_interval)
            except Exception as e:
                logger.exception(f"Alert monitoring error: {e}")
                await asyncio.sleep(self._check_interval)
    
    async def _check_all_rules(self):
        """ëª¨ë“  ì•Œë¦¼ ê·œì¹™ ì²´í¬"""
        for rule in self._alert_rules.values():
            if not rule.enabled:
                continue
                
            try:
                alert_event = await self._evaluate_rule(rule)
                if alert_event:
                    await self._send_alert(alert_event)
                    rule.last_triggered = datetime.now()
            except Exception as e:
                logger.exception(f"Error evaluating alert rule {rule.name}: {e}")
    
    async def _evaluate_rule(self, rule: AlertRule) -> Optional[AlertEvent]:
        """ì•Œë¦¼ ê·œì¹™ í‰ê°€"""
        # Cooldown ì²´í¬
        if rule.last_triggered:
            cooldown_delta = timedelta(minutes=rule.cooldown_minutes)
            if datetime.now() - rule.last_triggered < cooldown_delta:
                return None
        
        # ë©”íŠ¸ë¦­ ì¡°íšŒ
        metrics = self._metrics_collector.get_operation_metrics(
            rule.operation_name,
            rule.time_window
        )
        
        # ì¡°ê±´ë³„ í‰ê°€
        current_value = None
        message = ""
        
        if rule.condition == AlertCondition.ERROR_RATE_THRESHOLD:
            current_value = 1.0 - metrics.success_rate  # ì—ëŸ¬ìœ¨
            if current_value > rule.threshold_value:
                message = (
                    f"ì—ëŸ¬ìœ¨ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤: "
                    f"{current_value:.2%} > {rule.threshold_value:.2%}"
                )
        
        elif rule.condition == AlertCondition.RESPONSE_TIME_THRESHOLD:
            current_value = metrics.p90_response_time_ms
            if current_value > rule.threshold_value:
                message = (
                    f"ì‘ë‹µì‹œê°„(P90)ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤: "
                    f"{current_value:.2f}ms > {rule.threshold_value:.2f}ms"
                )
        
        elif rule.condition == AlertCondition.FAILURE_COUNT_THRESHOLD:
            current_value = metrics.failed_requests
            if current_value > rule.threshold_value:
                message = (
                    f"ì‹¤íŒ¨ ê±´ìˆ˜ê°€ ì„ê³„ê°’ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤: "
                    f"{current_value} > {rule.threshold_value}"
                )
        
        # ì•Œë¦¼ ì´ë²¤íŠ¸ ìƒì„±
        if current_value is not None and message:
            return AlertEvent(
                rule_name=rule.name,
                operation_name=rule.operation_name,
                severity=rule.severity,
                message=message,
                current_value=current_value,
                threshold_value=rule.threshold_value,
                timestamp=datetime.now(),
                metadata={
                    "time_window": rule.time_window,
                    "total_requests": metrics.total_requests,
                    "success_rate": metrics.success_rate
                }
            )
        
        return None
    
    async def _send_alert(self, alert_event: AlertEvent):
        """ì•Œë¦¼ ì „ì†¡"""
        for notifier in self._notifiers:
            try:
                success = await notifier.send_alert(alert_event)
                if not success:
                    logger.warning(f"Failed to send alert via {type(notifier).__name__}")
            except Exception as e:
                logger.exception(f"Alert notification error: {e}")
```

---

## ğŸ“Š ì„±ëŠ¥ ë° í’ˆì§ˆ ìš”êµ¬ì‚¬í•­

### ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
- ë¡œê¹… ì˜¤ë²„í—¤ë“œ: <5ms per operation
- ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì§€ì—°ì‹œê°„: <50ms
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€: <100MB (10,000ê°œ ë©”íŠ¸ë¦­ ê¸°ì¤€)
- ì•Œë¦¼ ë°˜ì‘ ì‹œê°„: <60ì´ˆ

### í’ˆì§ˆ ìš”êµ¬ì‚¬í•­
- ë¡œê·¸ ë°ì´í„° ë¬´ê²°ì„±: 99.9%
- ë©”íŠ¸ë¦­ ì •í™•ë„: 99.5%
- ì•Œë¦¼ ì •í™•ë„: 95% (false positive <5%)
- ì‹œìŠ¤í…œ ê°€ìš©ì„±: 99.9%

### í™•ì¥ì„± ìš”êµ¬ì‚¬í•­
- ë™ì‹œ ì‘ì—… ì²˜ë¦¬: 10,000+ operations/second
- ë©”íŠ¸ë¦­ ë³´ê´€ ê¸°ê°„: 30ì¼ (ìë™ ì•„ì¹´ì´ë¹™)
- ì•Œë¦¼ ê·œì¹™ ê°œìˆ˜: 100+ rules per operation
- ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ ì§€ì›: ë¶„ì‚° í™˜ê²½ì—ì„œ ë©”íŠ¸ë¦­ ì§‘ê³„

---

**ë¬¸ì„œ ìƒíƒœ**: ì„¤ê³„ ì™„ë£Œ, êµ¬í˜„ ëŒ€ê¸°  
**ë‹¤ìŒ ë‹¨ê³„**: í…ŒìŠ¤íŒ… í—¬í¼ ì‚¬ì–‘ ì‘ì„± ë° ì‹¤ì œ êµ¬í˜„